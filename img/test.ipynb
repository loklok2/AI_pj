{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash_attn\n",
      "  Using cached flash_attn-2.6.3.tar.gz (2.6 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [22 lines of output]\n",
      "      fatal: not a git repository (or any of the parent directories): .git\n",
      "      \n",
      "      \n",
      "      torch.__version__  = 2.4.0\n",
      "      \n",
      "      \n",
      "      C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-1ov0w0e9\\flash-attn_46f67047e9384ba0af8bbb99efe6946d\\setup.py:95: UserWarning: flash_attn was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n",
      "        warnings.warn(\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-install-1ov0w0e9\\flash-attn_46f67047e9384ba0af8bbb99efe6946d\\setup.py\", line 179, in <module>\n",
      "          CUDAExtension(\n",
      "        File \"C:\\Users\\user\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 1076, in CUDAExtension\n",
      "          library_dirs += library_paths(cuda=True)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\user\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 1214, in library_paths\n",
      "          paths.append(_join_cuda_home(lib_dir))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\user\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\utils\\cpp_extension.py\", line 2416, in _join_cuda_home\n",
      "          raise OSError('CUDA_HOME environment variable is not set. '\n",
      "      OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "! pip install flash_attn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
